ğŸš€ TubeTalk.ai API

TubeTalk.ai is a FastAPI-based backend that powers multiple AI services including:

RAG-based Chatbot

Quiz Generator

Summary Generator

Topic Extractor

It is modular, production-ready, and includes caching, logging middleware, and clean service architecture.

ğŸ§© Project Structure
app/
â”‚
â”œâ”€â”€ main.py                     # FastAPI app entry point
â”‚
â”œâ”€â”€ api/                        # All API route definitions
â”‚   â”œâ”€â”€ chatbot.py
â”‚   â”œâ”€â”€ quiz.py
â”‚   â”œâ”€â”€ summary.py
â”‚   â”œâ”€â”€ topics.py
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ cache/                      # Redis caching utilities
â”‚   â””â”€â”€ redis_cache.py
â”‚
â”œâ”€â”€ core/                       # Core logic (auth, config, etc.)
â”‚   â”œâ”€â”€ auth.py
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ database/                   # Database models, CRUD logic
â”‚   â”œâ”€â”€ crud.py
â”‚   â”œâ”€â”€ database.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ middleware/                 # Custom middleware
â”‚   â”œâ”€â”€ logging_middleware.py
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ pydantic_models/            # Pydantic schemas for validation
â”‚   â”œâ”€â”€ chatbot_model.py
â”‚   â”œâ”€â”€ quiz_model.py
â”‚   â”œâ”€â”€ summary_model.py
â”‚   â”œâ”€â”€ topics_model.py
â”‚   â”œâ”€â”€ __init__.py
â”‚
â”œâ”€â”€ services/                   # Business logic for each module
â”‚   â”œâ”€â”€ chat_service.py
â”‚   â”œâ”€â”€ quiz_service.py
â”‚   â”œâ”€â”€ summary_service.py
â”‚   â”œâ”€â”€ topics_service.py
â”‚   â”œâ”€â”€ __init__.py
â”‚
â””â”€â”€ utils/                      # Helper and utility functions
    â”œâ”€â”€ rag_utility.py
    â”œâ”€â”€ utility_functions.py
    â”œâ”€â”€ __init__.py

âš™ï¸ Setup Instructions
1. Clone the Repository
git clone https://github.com/<your-username>/tubetalk-ai-api.git
cd tubetalk-ai-api

2. Create a Virtual Environment
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows

3. Install Dependencies
pip install -r requirements.txt

4. Run Redis (for caching)

You can use Docker or a local Redis server:

docker run -d -p 6379:6379 redis

5. Start the FastAPI App
uvicorn app.main:app --reload

6. Visit the Docs

Interactive Swagger UI: ğŸ‘‰ http://localhost:8000/docs

ReDoc Documentation: ğŸ‘‰ http://localhost:8000/redoc

ğŸŒ API Endpoints
ğŸ§  Chatbot

Base URL: /chatbot

Method	Endpoint	Description
POST	/chatbot/query	Send a query to the RAG-based chatbot and receive a contextual answer.
ğŸ“ Summary Generator

Base URL: /summary

Method	Endpoint	Description
POST	/summary/generate	Generate a summarized version of provided content.
ğŸ¯ Quiz Generator

Base URL: /quiz

Method	Endpoint	Description
POST	/quiz/generate	Generate a quiz based on text, topics, or video transcript.
GET	/quiz/{quiz_id}	Retrieve details of a specific quiz.
ğŸ“š Topic Generator

Base URL: /topics

Method	Endpoint	Description
POST	/topics/generate	Extract key topics or concepts from text or transcript.
ğŸ§© Utility Endpoints
Method	Endpoint	Description
GET	/url/fetch	Fetch data from given URL (RAG use-case).
GET	/thread_id/get	Retrieve a unique thread/session ID.
DELETE	/thread_id/delete	Delete a thread from cache or memory.
ğŸ§  Middleware

LoggingMiddleware â†’ Logs all incoming requests and responses with timestamps and status codes.

ğŸ—„ï¸ Caching

Uses Redis for storing chatbot context, RAG retrieval cache, and quiz data for faster performance.

ğŸ“¦ Docker Setup (Optional)

You can run the app inside Docker:

docker build -t tubetalk-ai-api .
docker run -d -p 8000:8000 --name tubetalk-api tubetalk-ai-api

ğŸ§‘â€ğŸ’» Developer Notes

Python: >=3.9

Framework: FastAPI

Caching: Redis

Logging: Custom middleware + Uvicorn logs

Future plans: Authentication, API rate limiting, and analytics dashboard

â¤ï¸ Author

Pranay
Student AI Engineer | Machine Learning Enthusiast
GitHub: @pranay5519